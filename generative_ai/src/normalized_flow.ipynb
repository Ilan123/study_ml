{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c977bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Subset\n",
    "from torch import Tensor\n",
    "from typing import Tuple, Callable\n",
    "from itertools import chain\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f7978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41175/3266725043.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "scaler = GradScaler(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0ded18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='../data',\n",
    "    train=True,\n",
    "    # download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='../data',\n",
    "    train=False,\n",
    "    # download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1af4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 0\n",
    "training_data_incides = torch.where(training_data.targets == target_label)[0]\n",
    "test_data_incides = torch.where(test_data.targets == target_label)[0]\n",
    "\n",
    "training_data = Subset(training_data, training_data_incides)\n",
    "test_data = Subset(test_data, test_data_incides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b2abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation split fraction\n",
    "val_fraction = 0.1\n",
    "dataset_size = len(training_data)\n",
    "val_size = int(val_fraction * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "# Create a reproducible shuffled list of indices\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "indices = torch.randperm(dataset_size, generator=generator).tolist()\n",
    "\n",
    "# Split indices for train and validation\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# Wrap Subsets for train and validation datasets\n",
    "train_data = Subset(training_data, train_indices)\n",
    "val_data = Subset(training_data, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212d049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x):\n",
    "    \"\"\"Preprocess images for normalizing flow training\"\"\"\n",
    "    # Add uniform noise for dequantization (important for discrete data)\n",
    "    x = x + torch.rand_like(x) / 256.0\n",
    "    # Logit transform to map [0,1] to real numbers\n",
    "    x = torch.clamp(x, 1e-6, 1 - 1e-6)  # Avoid log(0)\n",
    "    x = torch.log(x) - torch.log(1 - x)  # logit transform\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143c8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderWrapper:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "\n",
    "def to_device(x: Tensor, y: Tensor) -> Tensor:\n",
    "    return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b973d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoaderWrapper(DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True), to_device)\n",
    "val_dataloader = DataLoaderWrapper(DataLoader(training_data, batch_size=batch_size), to_device)\n",
    "test_dataloader = DataLoaderWrapper(DataLoader(test_data, batch_size=batch_size), to_device)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a196257",
   "metadata": {},
   "source": [
    "$$\n",
    "z_B = \\exp\\left(-s(z_A)\\right) \\odot \\left(x_B - b(z_A)\\right)  \n",
    "$$\n",
    "\n",
    "$$\n",
    "J = \n",
    "\\begin{bmatrix}\n",
    "I_d & 0 \\\\\n",
    "\\frac{\\partial z_B}{\\partial x_A} & \\mathrm{diag}\\big(\\exp(-s)\\big)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_B = \\exp\\big(s(z_A, w)\\big) \\odot z_B + b(z_A, w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca5cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        split_at: int,\n",
    "        scale_net: nn.Module, # s\n",
    "        shift_net: nn.Module, # b\n",
    "        alternate_parts: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.split_at = split_at\n",
    "        self.scale_net = scale_net\n",
    "        self.shift_net = shift_net\n",
    "        self.alternate_parts = alternate_parts\n",
    "    \n",
    "\n",
    "    def _split(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        if self.alternate_parts:\n",
    "            return x[:, self.split_at:], x[:, :self.split_at]\n",
    "        else:\n",
    "            return x[:, :self.split_at], x[:, self.split_at:]\n",
    "\n",
    "\n",
    "    def _merge(self, xA: Tensor, xB: Tensor) -> Tensor:\n",
    "        if self.alternate_parts:\n",
    "            return torch.cat((xB, xA), dim=1)\n",
    "        else:\n",
    "            return torch.cat((xA, xB), dim=1)\n",
    "\n",
    "\n",
    "    def _get_scale_and_shift(self, zA: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        log_scale = self.scale_net(zA)\n",
    "        log_scale = torch.clamp(log_scale, min=-5, max=3)\n",
    "        shift = self.shift_net(zA)\n",
    "        return log_scale, shift\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, log_det_total: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        xA, xB = self._split(x)\n",
    "        zA = xA\n",
    "        log_scale, shift = self._get_scale_and_shift(zA)\n",
    "\n",
    "        zB = torch.exp(-log_scale) * (xB - shift)\n",
    "        z = self._merge(zA, zB)\n",
    "\n",
    "        log_det_current = -torch.sum(log_scale, dim=1)\n",
    "        log_det_total = log_det_total + log_det_current\n",
    "        return z, log_det_total\n",
    "\n",
    "\n",
    "    def inverse(self, z: Tensor) -> Tensor:\n",
    "        zA, zB = self._split(z)\n",
    "        xA = zA\n",
    "        log_scale, shift = self._get_scale_and_shift(zA)\n",
    "\n",
    "        xB = torch.exp(log_scale) * (zB + shift)\n",
    "        x = self._merge(xA, xB)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "        layers_dims: list,\n",
    "        activation_layer: nn.Module = nn.ReLU(),\n",
    "        bias: bool = True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        assert len(layers_dims) > 2\n",
    "        layers = []\n",
    "        \n",
    "        for in_features, out_features in zip(layers_dims[:-2], layers_dims[1:-1]):\n",
    "            layers.append(nn.Linear(in_features, out_features, bias=bias, device=device, dtype=dtype))\n",
    "            layers.append(copy.deepcopy(activation_layer))\n",
    "        \n",
    "        layers.append(nn.Linear(layers_dims[-2], layers_dims[-1], bias=bias, device=device, dtype=dtype))\n",
    "\n",
    "        # Init last layer to small values for stability\n",
    "        nn.init.zeros_(layers[-1].weight)\n",
    "        if bias:\n",
    "            nn.init.zeros_(layers[-1].bias)\n",
    "            \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        return self.model(x)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
