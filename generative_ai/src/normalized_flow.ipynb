{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c977bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Subset\n",
    "from torch import Tensor\n",
    "from typing import Tuple, Callable\n",
    "from itertools import chain\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f7978e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41175/3266725043.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "scaler = GradScaler(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0ded18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='../data',\n",
    "    train=True,\n",
    "    # download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='../data',\n",
    "    train=False,\n",
    "    # download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1af4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 0\n",
    "training_data_incides = torch.where(training_data.targets == target_label)[0]\n",
    "test_data_incides = torch.where(test_data.targets == target_label)[0]\n",
    "\n",
    "training_data = Subset(training_data, training_data_incides)\n",
    "test_data = Subset(test_data, test_data_incides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b2abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define validation split fraction\n",
    "val_fraction = 0.1\n",
    "dataset_size = len(training_data)\n",
    "val_size = int(val_fraction * dataset_size)\n",
    "train_size = dataset_size - val_size\n",
    "\n",
    "# Create a reproducible shuffled list of indices\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "indices = torch.randperm(dataset_size, generator=generator).tolist()\n",
    "\n",
    "# Split indices for train and validation\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:]\n",
    "\n",
    "# Wrap Subsets for train and validation datasets\n",
    "train_data = Subset(training_data, train_indices)\n",
    "val_data = Subset(training_data, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212d049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x):\n",
    "    \"\"\"Preprocess images for normalizing flow training\"\"\"\n",
    "    # Add uniform noise for dequantization (important for discrete data)\n",
    "    x = x + torch.rand_like(x) / 256.0\n",
    "    # Logit transform to map [0,1] to real numbers\n",
    "    x = torch.clamp(x, 1e-6, 1 - 1e-6)  # Avoid log(0)\n",
    "    x = torch.log(x) - torch.log(1 - x)  # logit transform\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143c8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderWrapper:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield (self.func(*b))\n",
    "\n",
    "\n",
    "def to_device(x: Tensor, y: Tensor) -> Tensor:\n",
    "    return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b973d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoaderWrapper(DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True), to_device)\n",
    "val_dataloader = DataLoaderWrapper(DataLoader(training_data, batch_size=batch_size), to_device)\n",
    "test_dataloader = DataLoaderWrapper(DataLoader(test_data, batch_size=batch_size), to_device)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a196257",
   "metadata": {},
   "source": [
    "$$\n",
    "z_B = \\exp\\left(-s(z_A)\\right) \\odot \\left(x_B - b(z_A)\\right)  \n",
    "$$\n",
    "\n",
    "$$\n",
    "J = \n",
    "\\begin{bmatrix}\n",
    "I_d & 0 \\\\\n",
    "\\frac{\\partial z_B}{\\partial x_A} & \\mathrm{diag}\\big(\\exp(-s)\\big)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_B = \\exp\\big(s(z_A, w)\\big) \\odot z_B + b(z_A, w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca5cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        split_at: int,\n",
    "        scale_net: nn.Module, # s\n",
    "        shift_net: nn.Module, # b\n",
    "        alternate_parts: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.split_at = split_at\n",
    "        self.scale_net = scale_net\n",
    "        self.shift_net = shift_net\n",
    "        self.alternate_parts = alternate_parts\n",
    "    \n",
    "\n",
    "    def _split(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        if self.alternate_parts:\n",
    "            return x[:, self.split_at:], x[:, :self.split_at]\n",
    "        else:\n",
    "            return x[:, :self.split_at], x[:, self.split_at:]\n",
    "\n",
    "\n",
    "    def _merge(self, xA: Tensor, xB: Tensor) -> Tensor:\n",
    "        if self.alternate_parts:\n",
    "            return torch.cat((xB, xA), dim=1)\n",
    "        else:\n",
    "            return torch.cat((xA, xB), dim=1)\n",
    "\n",
    "\n",
    "    def _get_scale_and_shift(self, zA: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        log_scale = self.scale_net(zA)\n",
    "        log_scale = torch.clamp(log_scale, min=-5, max=3)\n",
    "        shift = self.shift_net(zA)\n",
    "        return log_scale, shift\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, log_det_total: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        xA, xB = self._split(x)\n",
    "        zA = xA\n",
    "        log_scale, shift = self._get_scale_and_shift(zA)\n",
    "\n",
    "        zB = torch.exp(-log_scale) * (xB - shift)\n",
    "        z = self._merge(zA, zB)\n",
    "\n",
    "        log_det_current = -torch.sum(log_scale, dim=1)\n",
    "        log_det_total = log_det_total + log_det_current\n",
    "        return z, log_det_total\n",
    "\n",
    "\n",
    "    def inverse(self, z: Tensor) -> Tensor:\n",
    "        zA, zB = self._split(z)\n",
    "        xA = zA\n",
    "        log_scale, shift = self._get_scale_and_shift(zA)\n",
    "\n",
    "        xB = torch.exp(log_scale) * (zB + shift)\n",
    "        x = self._merge(xA, xB)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9159f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "        layers_dims: list,\n",
    "        activation_layer: nn.Module = nn.ReLU(),\n",
    "        bias: bool = True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        assert len(layers_dims) > 2\n",
    "        layers = []\n",
    "        \n",
    "        for in_features, out_features in zip(layers_dims[:-2], layers_dims[1:-1]):\n",
    "            layers.append(nn.Linear(in_features, out_features, bias=bias, device=device, dtype=dtype))\n",
    "            layers.append(copy.deepcopy(activation_layer))\n",
    "        \n",
    "        layers.append(nn.Linear(layers_dims[-2], layers_dims[-1], bias=bias, device=device, dtype=dtype))\n",
    "\n",
    "        # Init last layer to small values for stability\n",
    "        nn.init.zeros_(layers[-1].weight)\n",
    "        if bias:\n",
    "            nn.init.zeros_(layers[-1].bias)\n",
    "            \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        func: Callable[[Tensor], Tensor],\n",
    "        inv_func: Callable[[Tensor], Tensor],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.inv_func = inv_func\n",
    "\n",
    "    def forward(self, x: Tensor, *args, **kwargs):\n",
    "        y = self.func(x)\n",
    "        if args or kwargs:\n",
    "            return (y, *args) if not kwargs else (y, *args, kwargs)\n",
    "        return y\n",
    "    \n",
    "    def inverse(self, x: Tensor) -> Tensor:\n",
    "        return self.inv_func(x)\n",
    "\n",
    "\n",
    "def vec_to_img(x: Tensor) -> Tensor:\n",
    "    return x.view(-1, 1, 28, 28)\n",
    "\n",
    "def img_to_vec(x: Tensor) -> Tensor:\n",
    "    return x.flatten(1)\n",
    "\n",
    "\n",
    "def sigmoid_inverse(x: Tensor):\n",
    "    # Avoid log(0)\n",
    "    x = torch.clamp(x, 1e-6, 1 - 1e-6)\n",
    "    x = torch.log(x) - torch.log(1 - x)\n",
    "    return x\n",
    "\n",
    "def add_noise(x: Tensor):\n",
    "    # Add uniform noise for dequantization (important for discrete data)\n",
    "    return x + torch.rand_like(x) / 256.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowSequential(nn.Module):\n",
    "    def __init__(self, data_dim: int, *layers: nn.Module):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        # Check if all modules implement required interface\n",
    "        for i, module in enumerate(self.layers):\n",
    "            if not hasattr(module, 'forward') or not hasattr(module, 'inverse'):\n",
    "                raise TypeError(f\"Module at index {i} must implement both 'forward' and 'inverse' methods.\")\n",
    "            \n",
    "        self.register_buffer('base_mean', torch.zeros(data_dim))\n",
    "        self.register_buffer('base_cov', torch.eye(data_dim))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        log_det:\n",
    "        torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        for module in self.layers:\n",
    "            x, log_det = module(x, log_det)\n",
    "        return x, log_det\n",
    "\n",
    "    def inverse(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        for module in reversed(self.layers):\n",
    "            z = module.inverse(z)\n",
    "        return z\n",
    "    \n",
    "    def __call__(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        log_det: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Optional: put extra logic here before/after forward\n",
    "        return self.forward(x, log_det)\n",
    "    \n",
    "    def sample(self, num_samples: int, device:str=device) -> Tensor:\n",
    "        base_dist = MultivariateNormal(self.base_mean, self.base_cov)\n",
    "        z = base_dist.sample((num_samples,)).to(device)\n",
    "        \n",
    "        # Transform through inverse flow\n",
    "        with torch.no_grad():\n",
    "            x = self.inverse(z)\n",
    "        return x\n",
    "    \n",
    "    def log_prob(self, x: Tensor):\n",
    "        z, log_det = self.forward(x)\n",
    "        \n",
    "        base_dist = MultivariateNormal(self.base_mean, self.base_cov)\n",
    "        log_prob_base = base_dist.log_prob(z)\n",
    "        \n",
    "        log_prob = log_prob_base + log_det\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfde2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For implementation challange\n",
    "NORMAL_DIST_CONST = torch.log(torch.tensor(2 * torch.pi, device=device))\n",
    "def normal_NLL(X: Tensor) -> Tensor:\n",
    "    \"\"\"Compute -log p(z) for standard Gaussian\"\"\"\n",
    "    d = X.shape[1]\n",
    "    const_term = (d / 2) * NORMAL_DIST_CONST.to(X.device)\n",
    "    squared_term = 0.5 * X.pow(2).sum(dim=1)\n",
    "    return const_term + squared_term\n",
    "\n",
    "\n",
    "def flow_NLL_loss(\n",
    "    z_sample: Tensor,\n",
    "    total_log_det: Tensor,\n",
    ") -> Tensor:\n",
    "    \"\"\"Flow loss = base NLL - total log det (averaged)\"\"\"\n",
    "    return torch.mean(normal_NLL(z_sample) - total_log_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73781f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(x: Tensor, epoch=None):\n",
    "    \"\"\"Visualize samples from the trained model\"\"\"\n",
    "    # Plot samples\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(8, 2))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(x[i], cmap='gray')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    title = f'Generated Samples - Epoch {epoch}' if epoch else 'Generated Samples'\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 1])  # Leave space for suptitle\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
