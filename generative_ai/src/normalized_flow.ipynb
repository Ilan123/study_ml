{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c977bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Subset\n",
    "from torch import Tensor\n",
    "from typing import Tuple, Callable\n",
    "from itertools import chain\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0ded18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='../data',\n",
    "    train=True,\n",
    "    # download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='../data',\n",
    "    train=False,\n",
    "    # download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1af4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 0\n",
    "training_data_incides = torch.where(training_data.targets == target_label)[0]\n",
    "test_data_incides = torch.where(test_data.targets == target_label)[0]\n",
    "\n",
    "training_data = Subset(training_data, training_data_incides)\n",
    "test_data = Subset(test_data, test_data_incides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143c8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderWrapper:\n",
    "    def __init__(self, dl: DataLoader, desiried_labels: torch.Tensor):\n",
    "        self.dl = dl\n",
    "        self.desiried_labels = torch.tensor(desiried_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for X, y in self.dl:\n",
    "            mask = torch.isin(y, self.desiried_labels)\n",
    "            yield X[mask], y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b973d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([32, 1, 28, 28])\n",
      "Shape of y: torch.Size([32]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoaderWrapper(DataLoader(training_data, batch_size=batch_size), [0])\n",
    "test_dataloader = DataLoaderWrapper(DataLoader(test_data, batch_size=batch_size), [0])\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a196257",
   "metadata": {},
   "source": [
    "$$\n",
    "z_B = \\exp\\left(-s(z_A)\\right) \\odot \\left(x_B - b(z_A)\\right)  \n",
    "$$\n",
    "\n",
    "$$\n",
    "J = \n",
    "\\begin{bmatrix}\n",
    "I_d & 0 \\\\\n",
    "\\frac{\\partial z_B}{\\partial x_A} & \\mathrm{diag}\\big(\\exp(-s)\\big)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_B = \\exp\\big(s(z_A, w)\\big) \\odot z_B + b(z_A, w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cca5cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CouplingLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        split_at: int,\n",
    "        scale_net: nn.Module, # s\n",
    "        shift_net: nn.Module, # b\n",
    "        alternate_parts: bool = False\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.split_at = split_at\n",
    "        self.scale_net = scale_net\n",
    "        self.shift_net = shift_net\n",
    "        self.alternate_parts = alternate_parts\n",
    "    \n",
    "\n",
    "    def _split(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        if self.alternate_parts:\n",
    "            return x[:, self.split_at:], x[:, :self.split_at]\n",
    "        else:\n",
    "            return x[:, :self.split_at], x[:, self.split_at:]\n",
    "\n",
    "\n",
    "    def _merge(self, xA: Tensor, xB: Tensor) -> Tensor:\n",
    "        if self.alternate_parts:\n",
    "            return torch.cat((xB, xA), dim=1)\n",
    "        else:\n",
    "            return torch.cat((xA, xB), dim=1)\n",
    "\n",
    "\n",
    "    def _get_scale_and_shift(self, zA: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        log_scale = self.scale_net(zA)\n",
    "        log_scale = torch.clamp(log_scale, min=self.log_scale_min, max=self.log_scale_max)\n",
    "        shift = self.shift_net(zA)\n",
    "        return log_scale, shift\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor, log_det_total: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        xA, xB = self._split(x)\n",
    "        zA = xA\n",
    "        log_scale, shift = self._get_scale_and_shift(zA)\n",
    "\n",
    "        zB = torch.exp(-log_scale) * (xB - shift)\n",
    "        z = self._merge(zA, zB)\n",
    "\n",
    "        log_det_current = -torch.sum(log_scale, dim=1)\n",
    "        log_det_total = log_det_total + log_det_current\n",
    "        return z, log_det_total\n",
    "\n",
    "\n",
    "    def inverse(self, z: Tensor) -> Tensor:\n",
    "        zA, zB = self._split(z)\n",
    "        xA = zA\n",
    "        log_scale, shift = self._get_scale_and_shift(zA)\n",
    "\n",
    "        xB = torch.exp(log_scale) * (zB + shift)\n",
    "        x = self._merge(xA, xB)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearActivationStack(nn.Module):\n",
    "    def __init__(self,\n",
    "        num_of_layers: int,\n",
    "        in_features: int,\n",
    "        activation_layer: nn.Module = nn.ReLU(),\n",
    "        bias: bool = True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.activation_layer = activation_layer\n",
    "        layers = chain.from_iterable(\n",
    "            (\n",
    "                nn.Linear(in_features, in_features, bias=bias, device=device, dtype=dtype),\n",
    "                # Clone to avoid shared state\n",
    "                copy.deepcopy(activation_layer)\n",
    "            )\n",
    "            for _ in range(num_of_layers)\n",
    "        )\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x) -> Tensor:\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8c2f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dActivationStack(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_of_layers: int,\n",
    "        in_channels: int,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        padding: int = 1,\n",
    "        activation_layer: nn.Module = nn.ReLU(),\n",
    "        bias: bool = True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "        input_is_flat: bool = False,      # New flag\n",
    "        image_shape: tuple[int, int, int] = None  # (C, H, W)\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.activation_layer = activation_layer\n",
    "        self.input_is_flat = input_is_flat\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "        layers = chain.from_iterable(\n",
    "            (\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    in_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    bias=bias,\n",
    "                    device=device,\n",
    "                    dtype=dtype,\n",
    "                ),\n",
    "                # Clone to avoid shared state\n",
    "                copy.deepcopy(activation_layer) \n",
    "            )\n",
    "            for _ in range(num_of_layers)\n",
    "        )\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "        if self.input_is_flat:\n",
    "            assert (\n",
    "                self.image_shape is not None\n",
    "            ), \"Must provide image_shape if input_is_flat is True\"\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.input_is_flat:\n",
    "            # reshape flat vector to image tensor\n",
    "            B = x.size(0)\n",
    "            x = x.view(B, *self.image_shape)  # (B, C, H, W)\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        if self.input_is_flat:\n",
    "            # flatten back to vector\n",
    "            B = x.size(0)\n",
    "            x = x.view(B, -1)  # (B, C*H*W)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48338750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        func: Callable[[Tensor], Tensor],\n",
    "        inv_func: Callable[[Tensor], Tensor],\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.inv_func = inv_func\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.func(x)\n",
    "    \n",
    "    def inverse(self, x: Tensor) -> Tensor:\n",
    "        return self.inv_func(x)\n",
    "\n",
    "\n",
    "def vec_to_img(x: Tensor) -> Tensor:\n",
    "    return x.view(-1, 1, 28, 28)\n",
    "\n",
    "def img_to_vec(x: Tensor) -> Tensor:\n",
    "    return x.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b40c6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowSequential(nn.Module):\n",
    "    def __init__(self, *modules: nn.Module):\n",
    "        super().__init__()\n",
    "        self.modules_list = nn.ModuleList(modules)\n",
    "\n",
    "        # Check if all modules implement required interface\n",
    "        for i, module in enumerate(self.modules_list):\n",
    "            if not hasattr(module, 'forward') or not hasattr(module, 'inverse'):\n",
    "                raise TypeError(f\"Module at index {i} must implement both 'forward' and 'inverse' methods.\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor, log_det: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        for module in self.modules_list:\n",
    "            x, log_det = module(x, log_det)\n",
    "        return x, log_det\n",
    "\n",
    "    def inverse(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        for module in reversed(self.modules_list):\n",
    "            z = module.inverse(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FlowSequential(\n",
    "    LambdaLayer(img_to_vec, vec_to_img),\n",
    "    CouplingLayer(LinearActivationStack()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42f2416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_to_img(LambdaLayer(img_to_vec, vec_to_img)(training_data[0][0])).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
