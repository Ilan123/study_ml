{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.utils.data import Subset\n",
    "from torch import Tensor\n",
    "from typing import Tuple, Callable\n",
    "from itertools import chain\n",
    "import copy\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.distributions import MultivariateNormal\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44147749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17802/3266725043.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "scaler = GradScaler(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangevinSampling:\n",
    "    def __init__(\n",
    "            self,\n",
    "            model: Callable,\n",
    "            batch_size: int,\n",
    "            sample_size: list,\n",
    "            refresh_prob: float,\n",
    "            n_steps: int,\n",
    "            step_size: float,\n",
    "            noise_scale: float,\n",
    "            device: str,\n",
    "        ):\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_size = sample_size\n",
    "        self.refresh_prob = refresh_prob.to(device)\n",
    "        self.n_steps = n_steps\n",
    "        self.step_size = step_size\n",
    "        self.noise_scale = noise_scale\n",
    "        self.device = device\n",
    "        self.buffer = 2*torch.rand([batch_size, *sample_size], device=device) - 1\n",
    "\n",
    "\n",
    "    def _get_refresh_indices(self):\n",
    "        mask = torch.rand(self.sample_size, device=self.device) < self.refresh_prob\n",
    "        indexes_to_refresh = torch.nonzero(mask, as_tuple=True)[0]\n",
    "        return indexes_to_refresh\n",
    "    \n",
    "\n",
    "    def _refresh_chains(self):\n",
    "        indexes_to_refresh = self._get_refresh_indices()\n",
    "        n_new = len(indexes_to_refresh)\n",
    "        self.buffer[indexes_to_refresh] = 2*torch.rand([n_new, *self.sample_size], device=device) - 1\n",
    "    \n",
    "\n",
    "    def _compute_per_chain_grads(self, x: Tensor):\n",
    "        x.requires_grad_()\n",
    "        y = self.model(x)\n",
    "\n",
    "        grads = []\n",
    "        for i in range(x.size(0)):\n",
    "            grad_i = torch.autograd.grad(\n",
    "                y[i], x, retain_graph=True, create_graph=True\n",
    "            )[0][i]\n",
    "            grads.append(grad_i)\n",
    "\n",
    "        return torch.stack(grads)\n",
    "    \n",
    "\n",
    "    def _langevin_step(self, x: Tensor):\n",
    "        noise = self.noise_scale * (2*torch.rand_like(x) - 1)\n",
    "        grad = self.batch_size*self._compute_per_chain_grads(x)\n",
    "        self.buffer += grad + noise\n",
    "\n",
    "\n",
    "    def persist_sample(self):\n",
    "        self._refresh_chains()\n",
    "        for _ in range(self.n_steps):\n",
    "            self._langevin_step(self.buffer)\n",
    "\n",
    "        return self.buffer\n",
    "    \n",
    "\n",
    "    def sample(self, batch_size: int, n_steps: Union[int, None] = None):\n",
    "        if n_steps is None:\n",
    "            n_steps = self.n_steps\n",
    "\n",
    "        x = 2*torch.rand([batch_size, *self.sample_size], device=device) - 1\n",
    "        for _ in range(n_steps):\n",
    "            self._langevin_step(x)\n",
    "\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
